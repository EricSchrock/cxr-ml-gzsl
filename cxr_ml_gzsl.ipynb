{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CXR-ML-GZSL"
      ],
      "metadata": {
        "id": "6bKRAGBpLskG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview\n",
        "\n",
        "The goal of this notebook is to reproduce the findings of the paper, \"Multi-Label Generalized Zero Shot Learning for the Classification of Disease in Chest Radiographs\" with the help of an LLM. The paper provides code, but this notebook only directly reuses the provided split of the dataset into training, test, and validation data. The provided code was a valuable reference during the development of this notebook.\n",
        "\n",
        "* Paper: https://arxiv.org/abs/2107.06563\n",
        "* Dataset split: https://github.com/nyuad-cai/CXR-ML-GZSL/tree/master/dataset_splits\n",
        "\n",
        "The paper uses a dataset, initially known as `ChestX-ray8`, but then renamed to `ChestX-ray14` when the dataset was expanded from eight to fourteen distinct disease labels. The dataset contains 112120 labeled chest X-rays.\n",
        "\n",
        "* Dataset paper: https://arxiv.org/abs/1705.02315\n",
        "* Dataset: https://nihcc.app.box.com/v/ChestXray-NIHCC/folder/36938765345\n",
        "\n",
        "The dataset provides an example of how to download the chext X-ray images and a spreadsheet mapping images to classification labels. However, the \"dataset split\" files already contain the image classification labels so this notebook will not use the spreadsheet.\n",
        "\n",
        "* Download script: https://nihcc.app.box.com/v/ChestXray-NIHCC/file/371647823217\n",
        "* Labels: https://nihcc.app.box.com/v/ChestXray-NIHCC/file/219760887468\n",
        "\n",
        "**Note**: The dataset is ~42 GB. Expect significant download times."
      ],
      "metadata": {
        "id": "ijYrSzRsLDkQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment"
      ],
      "metadata": {
        "id": "ig7PMke4LVnl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!if command -v nvidia-smi &> /dev/null; then nvidia-smi --query-gpu=name --format=csv,noheader; else echo 'No NVIDIA GPU detected'; fi\n",
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnctIu-gLZp5",
        "outputId": "1b5345db-af1a-4e28-c498-108089b7acd2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA A100-SXM4-40GB\n",
            "Python 3.11.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "import os\n",
        "import requests\n",
        "import tarfile\n",
        "import urllib.request\n",
        "\n",
        "import PIL\n",
        "from PIL import Image\n",
        "\n",
        "print(f\"PIL: {PIL.__version__}\")\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "print(f\"torch: {torch.__version__}\")\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "print(f\"torchvision: {torchvision.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0x5zopuELPXB",
        "outputId": "b846c7e7-2bce-49fe-c739-144556a3fdac"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PIL: 11.1.0\n",
            "torch: 2.6.0+cu124\n",
            "torchvision: 0.21.0+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download"
      ],
      "metadata": {
        "id": "2Gwu5wJDLaJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for filename in [\"train.txt\", \"val.txt\", \"test.txt\"]:\n",
        "    response = requests.get(f\"https://raw.githubusercontent.com/nyuad-cai/CXR-ML-GZSL/master/dataset_splits/{filename}\")\n",
        "\n",
        "    with open(filename, \"w\") as f:\n",
        "        f.write(response.text)\n",
        "\n",
        "    print(f\"Downloaded: {filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIC65QJdLeEb",
        "outputId": "5bf811e3-8081-458c-da8f-5491ced3bdb2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded: train.txt\n",
            "Downloaded: val.txt\n",
            "Downloaded: test.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = [\n",
        "    {\"filename\": \"images_001.tar.gz\", \"url\": \"https://nihcc.box.com/shared/static/vfk49d74nhbxq3nqjg0900w5nvkorp5c.gz\"} #todo: Add the rest of the dataset\n",
        "]\n",
        "\n",
        "for item in dataset:\n",
        "    filename = item[\"filename\"]\n",
        "    url = item[\"url\"]\n",
        "\n",
        "    urllib.request.urlretrieve(url, filename)\n",
        "\n",
        "    with tarfile.open(filename, \"r:gz\") as tar:\n",
        "        tar.extractall()\n",
        "\n",
        "    os.remove(filename)\n",
        "\n",
        "    print(f\"Downloaded and extracted: {filename}\")\n",
        "\n",
        "IMAGE_PATH = \"images\"\n",
        "NUM_IMAGES = 112120\n",
        "\n",
        "assert os.path.exists(IMAGE_PATH), \"Dataset is not in the expected directory!\"\n",
        "# assert len([f for f in os.listdir(IMAGE_PATH) if os.path.isfile(os.path.join(IMAGE_PATH, f))]) == NUM_IMAGES, \"Dataset is not the expected size!\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVF2OYbERAcX",
        "outputId": "f3c7b1fc-7650-4119-a0cc-4f8cb3b198f2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded and extracted: images_001.tar.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "RbXv4b33LekL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ChestXrayDataset(Dataset):\n",
        "    def __init__(self, image_dir, labels_file, num_classes, transform):\n",
        "        self.image_dir = image_dir\n",
        "        self.num_classes = num_classes\n",
        "        self.transform = transform\n",
        "        self.samples = []\n",
        "\n",
        "        with open(labels_file, 'r') as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                image_name = os.path.basename(parts[0]) # remove <path>/ from <path>/<image_name>\n",
        "\n",
        "                if not os.path.isfile(f\"{self.image_dir}/{image_name}\"): #todo: Remove once we add the full database\n",
        "                    continue\n",
        "\n",
        "                labels = list(map(int, parts[1:self.num_classes + 1]))\n",
        "                self.samples.append((image_name, labels))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_name, label = self.samples[idx]\n",
        "        image_path = os.path.join(self.image_dir, image_name)\n",
        "\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        image = self.transform(image)\n",
        "\n",
        "        label = torch.tensor(label, dtype=torch.int)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "XQXR2pkJLmi7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**: The validation dataset is not for tuning hyperparameters, but to measure the training loss. Cross-validation is not used."
      ],
      "metadata": {
        "id": "UoIFT5E-4xMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Credit: https://github.com/nyuad-cai/CXR-ML-GZSL/blob/master/ChexnetTrainer.py#L104-L130\n",
        "# Credit: https://github.com/nyuad-cai/CXR-ML-GZSL/blob/master/arguments.py#L22-L23\n",
        "\n",
        "normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "\n",
        "training_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "])\n",
        "\n",
        "testing_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.TenCrop(224),\n",
        "    transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n",
        "    transforms.Lambda(lambda crops: torch.stack([normalize(crop) for crop in crops]))\n",
        "])\n",
        "\n",
        "train_data = ChestXrayDataset(IMAGE_PATH, \"train.txt\", num_classes=10, transform=training_transform)\n",
        "val_data   = ChestXrayDataset(IMAGE_PATH, \"val.txt\",   num_classes=10, transform=testing_transform)\n",
        "test_data  = ChestXrayDataset(IMAGE_PATH, \"test.txt\",  num_classes=14, transform=testing_transform)\n",
        "\n",
        "print(f\"Training samples: {len(train_data)}\")\n",
        "print(f\"Validation samples: {len(val_data)}\")\n",
        "print(f\"Testing samples: {len(test_data)}\")\n",
        "\n",
        "# assert len(train_data) == 30758, \"Training dataset is not the right size!\" #todo: Add once we add the full database\n",
        "# assert len(val_data) == 4474, \"Validation dataset is not the right size!\"\n",
        "# assert len(test_data) == 10510, \"Test dataset is not the right size!\"\n",
        "\n",
        "assert multiprocessing.cpu_count() > 10, f\"CPU only has {multiprocessing.cpu_count()} cores\"\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=16,    shuffle=True,  num_workers=10, pin_memory=True)\n",
        "val_loader   = DataLoader(val_data,   batch_size=16*10, shuffle=False, num_workers=10, pin_memory=True)\n",
        "test_loader  = DataLoader(test_data,  batch_size=16*3,  shuffle=False, num_workers=10, pin_memory=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJ0cD0Oms8tx",
        "outputId": "dc596741-934d-41c0-8055-fb8d541bdbf7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 3544\n",
            "Validation samples: 410\n",
            "Testing samples: 1045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "9DuhrErYLocv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XUMmlAk2Lpk6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "GbKfCp0zLp44"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RDanD5MEcV0_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "x89hnxU-cWGG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xFUZsa4mcYgY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results"
      ],
      "metadata": {
        "id": "kMdzScKScZAd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jKmO6PLKcaan"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}
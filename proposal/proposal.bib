@misc{hayat2021multilabel,
      title={Multi-Label Generalized Zero Shot Learning for the Classification of Disease in Chest Radiographs}, 
      author={Nasir Hayat and Hazem Lashen and Farah E. Shamout},
      year={2021},
      eprint={2107.06563},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{10.1109/TPAMI.2012.256,
author = {Scheirer, Walter and Rocha, Anderson and Sapkota, Archana and Boult, Terrance},
title = {Toward Open Set Recognition},
year = {2013},
issue_date = {July 2013},
publisher = {IEEE Computer Society},
address = {USA},
volume = {35},
number = {7},
issn = {0162-8828},
url = {https://doi.org/10.1109/TPAMI.2012.256},
doi = {10.1109/TPAMI.2012.256},
abstract = {To date, almost all experimental evaluations of machine learning-based recognition algorithms in computer vision have taken the form of “closed set” recognition, whereby all testing classes are known at training time. A more realistic scenario for vision applications is “open set” recognition, where incomplete knowledge of the world is present at training time, and unknown classes can be submitted to an algorithm during testing. This paper explores the nature of open set recognition and formalizes its definition as a constrained minimization problem. The open set recognition problem is not well addressed by existing algorithms because it requires strong generalization. As a step toward a solution, we introduce a novel “1-vs-set machine,” which sculpts a decision space from the marginal distances of a 1-class or binary SVM with a linear kernel. This methodology applies to several different applications in computer vision where open set recognition is a challenging problem, including object recognition and face verification. We consider both in this work, with large scale cross-dataset experiments performed over the Caltech 256 and ImageNet sets, as well as face matching experiments performed over the Labeled Faces in the Wild set. The experiments highlight the effectiveness of machines adapted for open set evaluation compared to existing 1-class and binary SVMs for the same tasks.},
journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
month = jul,
pages = {1757–1772},
numpages = {16},
keywords = {support vector machines, object recognition, machine learning, face verification, Training data, Training, Testing, Support vector machines, Open set recognition, Object recognition, Face recognition, Face, 1-vs-set machine}
}

@article{10.1109/TMM.2019.2924511,
author = {Rahman, Shafin and Khan, Salman and Barnes, Nick},
title = {Deep0Tag: Deep Multiple Instance Learning for Zero-Shot Image Tagging},
year = {2020},
issue_date = {Jan. 2020},
publisher = {IEEE Press},
volume = {22},
number = {1},
issn = {1520-9210},
url = {https://doi.org/10.1109/TMM.2019.2924511},
doi = {10.1109/TMM.2019.2924511},
abstract = {Zero-shot learning aims to perform visual reasoning about unseen objects. In-line with the success of deep learning on object recognition problems, several end-to-end deep models for zero-shot recognition have been proposed in the literature. These models are successful in predicting a single unseen label given an input image but do not scale to cases where multiple unseen objects are present. Here, we focus on the challenging problem of <italic>zero-shot image tagging</italic>, where multiple labels are assigned to an image, that may relate to objects, attributes, actions, events, and scene type. Discovery of these scene concepts requires the ability to process multi-scale information. To encompass global as well as local image details, we propose an automatic approach to locate relevant image patches and model image tagging within the Multiple Instance Learning (MIL) framework. To the best of our knowledge, we propose the first end-to-end trainable deep MIL framework for the multi-label zero-shot tagging problem. We explore several alternatives for instance-level evidence aggregation and perform an extensive ablation study to identify the optimal pooling strategy. Due to its novel design, the proposed framework has several interesting features: 1) unlike previous deep MIL models, it does not use any off-line procedure (e.g., Selective Search or EdgeBoxes) for bag generation. 2) During test time, it can process any number of unseen labels given their semantic embedding vectors. 3) Using only image-level seen labels as weak annotation, it can produce a localized bounding box for each predicted label. We experiment with the large-scale NUS-WIDE and MS-COCO datasets and achieve superior performance across conventional, zero-shot, and generalized zero-shot tagging tasks.},
journal = {Trans. Multi.},
month = jan,
pages = {242–255},
numpages = {14}
}

@INPROCEEDINGS{9157745,
  author={Huynh, Dat and Elhamifar, Ehsan},
  booktitle={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={A Shared Multi-Attention Framework for Multi-Label Zero-Shot Learning}, 
  year={2020},
  volume={},
  number={},
  pages={8773-8783},
  keywords={Training;Image recognition;Semantics;Feature extraction;Task analysis;Complexity theory;Computational modeling},
  doi={10.1109/CVPR42600.2020.00880}}

@misc{dinu2015improvingzeroshotlearningmitigating,
      title={Improving zero-shot learning by mitigating the hubness problem}, 
      author={Georgiana Dinu and Angeliki Lazaridou and Marco Baroni},
      year={2015},
      eprint={1412.6568},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1412.6568}, 
}

@article{10.1093/bioinformatics/btz682,
    author = {Lee, Jinhyuk and Yoon, Wonjin and Kim, Sungdong and Kim, Donghyeon and Kim, Sunkyu and So, Chan Ho and Kang, Jaewoo},
    title = {BioBERT: a pre-trained biomedical language representation model for biomedical text mining},
    journal = {Bioinformatics},
    volume = {36},
    number = {4},
    pages = {1234-1240},
    year = {2019},
    month = {09},
    abstract = {Biomedical text mining is becoming increasingly important as the number of biomedical documents rapidly grows. With the progress in natural language processing (NLP), extracting valuable information from biomedical literature has gained popularity among researchers, and deep learning has boosted the development of effective biomedical text mining models. However, directly applying the advancements in NLP to biomedical text mining often yields unsatisfactory results due to a word distribution shift from general domain corpora to biomedical corpora. In this article, we investigate how the recently introduced pre-trained language model BERT can be adapted for biomedical corpora.We introduce BioBERT (Bidirectional Encoder Representations from Transformers for Biomedical Text Mining), which is a domain-specific language representation model pre-trained on large-scale biomedical corpora. With almost the same architecture across tasks, BioBERT largely outperforms BERT and previous state-of-the-art models in a variety of biomedical text mining tasks when pre-trained on biomedical corpora. While BERT obtains performance comparable to that of previous state-of-the-art models, BioBERT significantly outperforms them on the following three representative biomedical text mining tasks: biomedical named entity recognition (0.62\% F1 score improvement), biomedical relation extraction (2.80\% F1 score improvement) and biomedical question answering (12.24\% MRR improvement). Our analysis results show that pre-training BERT on biomedical corpora helps it to understand complex biomedical texts.We make the pre-trained weights of BioBERT freely available at https://github.com/naver/biobert-pretrained, and the source code for fine-tuning BioBERT available at https://github.com/dmis-lab/biobert.},
    issn = {1367-4803},
    doi = {10.1093/bioinformatics/btz682},
    url = {https://doi.org/10.1093/bioinformatics/btz682},
    eprint = {https://academic.oup.com/bioinformatics/article-pdf/36/4/1234/48983216/bioinformatics\_36\_4\_1234.pdf},
}

@misc{rajpurkar2017chexnetradiologistlevelpneumoniadetection,
      title={CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep Learning}, 
      author={Pranav Rajpurkar and Jeremy Irvin and Kaylie Zhu and Brandon Yang and Hershel Mehta and Tony Duan and Daisy Ding and Aarti Bagul and Curtis Langlotz and Katie Shpanskaya and Matthew P. Lungren and Andrew Y. Ng},
      year={2017},
      eprint={1711.05225},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1711.05225}, 
}

@misc{kingma2017adammethodstochasticoptimization,
      title={Adam: A Method for Stochastic Optimization}, 
      author={Diederik P. Kingma and Jimmy Ba},
      year={2017},
      eprint={1412.6980},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1412.6980}, 
}

@misc{lee2018multilabelzeroshotlearningstructured,
      title={Multi-Label Zero-Shot Learning with Structured Knowledge Graphs}, 
      author={Chung-Wei Lee and Wei Fang and Chih-Kuan Yeh and Yu-Chiang Frank Wang},
      year={2018},
      eprint={1711.06526},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1711.06526}, 
}

@inproceedings{Wang_2017,
   title={ChestX-Ray8: Hospital-Scale Chest X-Ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases},
   url={http://dx.doi.org/10.1109/CVPR.2017.369},
   DOI={10.1109/cvpr.2017.369},
   booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
   publisher={IEEE},
   author={Wang, Xiaosong and Peng, Yifan and Lu, Le and Lu, Zhiyong and Bagheri, Mohammadhadi and Summers, Ronald M.},
   year={2017},
   month=jul, pages={3462–3471} }
